{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image\n",
    "import os\n",
    "from Qwen2VL_uigraph.model.processing_qwen2_vl import Qwen2VLProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import ast  # To safely evaluate JSON-like strings\n",
    "from PIL import Image, ImageDraw\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw click point on image\n",
    "def draw_click_point(img_path, click_x, click_y, bbox, pred=False):\n",
    "    \"\"\"\n",
    "    img_path: str\n",
    "    click_x, click_y : ralative coordinate (0-1)\n",
    "    bbox, list : [x_low, y_low, x_high, y_high] (0-1)\n",
    "    pred : model prediction | ground truth\n",
    "        if ground truth, no output visualized image\n",
    "    \"\"\"\n",
    "    if os.path.exists(img_path):\n",
    "        img = Image.open(img_path)\n",
    "        w, h = img.size  # Get image dimensions\n",
    "        \n",
    "        # Convert relative to absolute coordinates\n",
    "        abs_x = int(click_x * w)\n",
    "        abs_y = int(click_y * h)\n",
    "        \n",
    "        # Draw the dot\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        dot_radius = 10  # Adjust dot size if needed\n",
    "        draw.ellipse((abs_x - dot_radius, abs_y - dot_radius, abs_x + dot_radius, abs_y + dot_radius), fill=\"red\")\n",
    "\n",
    "        # Draw the bounding box (if exists)\n",
    "        if bbox: # [0.278, 0.64, 0.528, 0.688]\n",
    "            bbox_x_top_left = round(bbox[0] * w)\n",
    "            bbox_y_top_left = round(bbox[1] * h)\n",
    "            bbox_x_bot_right = round(bbox[2] * w)\n",
    "            bbox_y_bot_right = round(bbox[3] * h)\n",
    "            \n",
    "            bbox_coords = [(bbox_x_top_left, bbox_y_top_left), (bbox_x_bot_right, bbox_y_bot_right)]\n",
    "            draw.rectangle(bbox_coords, outline=\"blue\", width=3)  # Blue bbox\n",
    "\n",
    "        # Save the modified image temporarily\n",
    "        if not pred:\n",
    "            temp_img_path = \"./visualize_imgs/image.png\"\n",
    "        else:\n",
    "            temp_img_path = \"./visualize_imgs/pred_image.png\"\n",
    "\n",
    "        img.save(temp_img_path)\n",
    "        # Return the new image path\n",
    "        return temp_img_path\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON file\n",
    "naive_json_path = \"/home/syc/intern/wanshan/Thesis_result/ScreenSpot/UIGraph/all/screenspot_qwen2vl-7b_dropratio-0.0_web.json\"\n",
    "\n",
    "with open(naive_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    naive_data = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "uigraph_json_path = \"/home/syc/intern/wanshan/Thesis_result/ScreenSpot/Prune_layer_2/screenspot_qwen2vl-7b_uigraph_dropratio-0.2_web-prune-layer_2.json\"\n",
    "with open(uigraph_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    uigraph_data = json.load(f)\n",
    "# Filter instances where Ele_match is False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_path': '/data/data1/syc/intern/wanshan/datasets/ScreenSpot/screenspot_imgs/mobile_1ca5b944-293a-46a1-af95-eb35bc8a0b2a.png',\n",
       " 'text': 'check the weather',\n",
       " 'bbox': [0.09449152542372881,\n",
       "  0.0475609756097561,\n",
       "  0.34915254237288135,\n",
       "  0.4091463414634146],\n",
       " 'pred': [0.19, 0.1],\n",
       " 'matched': True,\n",
       " 'response': '{\"action_type\": 4, \"click_point\": (0.19,0.10)}\\n',\n",
       " 'type': 'icon',\n",
       " 'source': 'ios'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uigraph_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09449152542372881,\n",
       " 0.0475609756097561,\n",
       " 0.34915254237288135,\n",
       " 0.4091463414634146]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_data[0]['bbox']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatched_idxs  = []\n",
    "for sample_idx, sample in enumerate(naive_data):\n",
    "    if 'matched' in sample and 'matched' in uigraph_data[sample_idx]:\n",
    "        if sample['matched'] == True and uigraph_data[sample_idx]['matched'] == False and 'web' in sample['img_path']:\n",
    "            mismatched_idxs.append(sample_idx)\n",
    "len(mismatched_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in mismatched_idxs:\n",
    "#     uigraph_data[idx]['pred'][1] += 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_idx in mismatched_idxs:\n",
    "    if naive_data[sample_idx]['img_path'] != uigraph_data[sample_idx]['img_path']:\n",
    "        print('mismatched image_path', naive_data[sample_idx]['img_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/data/data1/syc/intern/wanshan/models/Qwen2-VL-2B-Instruct\"\n",
    "# model_path = \"/data/data1/syc/intern/wanshan/models/showlab/ShowUI-2B_edited\"\n",
    "\n",
    "# min_pixel = 1344*28*28\n",
    "# max_pixel = 1680*28*28\n",
    "# 1. Screenshot -> Graph\n",
    "uigraph_train = True  # Enable ui graph during training\n",
    "uigraph_test = True  # Enable ui graph during inference\n",
    "uigraph_diff = 1  # Pixel difference used for constructing ui graph\n",
    "uigraph_rand = False  # Enable random graph construction\n",
    "# 2. Graph -> Mask\n",
    "uimask_pre = True  # Prebuild patch selection mask in the preprocessor (not in model layers) for efficiency\n",
    "uimask_ratio = 0.4  # Specify the percentage of patch tokens to skip per component\n",
    "uimask_rand = False  # Enable random token selection instead of uniform selection\n",
    "\n",
    "\n",
    "processor = Qwen2VLProcessor.from_pretrained(\n",
    "    model_path,\n",
    "    # min_pixels= min_pixel,\n",
    "    # max_pixels = max_pixel,\n",
    "    uigraph_train=uigraph_train,\n",
    "    uigraph_test=uigraph_test,\n",
    "    uigraph_diff=uigraph_diff,\n",
    "    uigraph_rand=uigraph_rand,\n",
    "    uimask_pre=True,\n",
    "    uimask_ratio=uimask_ratio,\n",
    "    uimask_rand=uimask_rand,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_visualize(image_path):\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image_path,\n",
    "                # \"min_pixels\": min_pixel,\n",
    "                # \"max_pixels\": max_pixel,\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "        ],\n",
    "    }\n",
    "    ]\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, _ = process_vision_info(messages)\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "        vis_dir=\"./visualize_imgs\" # this folder to save visualization \n",
    "    )\n",
    "    with open(\"./visualize_imgs/demo.png\", \"rb\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5608866c20424f7b8c36dfcdf9240e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='**Naive Action(s):** {\\'img_path\\': \\'/data/data1/syc/intern/wanshan/datasets/ScreenSpot/screenspo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6a7cd51c0747f0a8d445c89b601d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='**UI Graph Action(s):** {\\'img_path\\': \\'/data/data1/syc/intern/wanshan/datasets/ScreenSpot/screen…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bb84f5bc194b3b8ea4b22b87630c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\n\\x00\\x00\\x00\\x05\\xa0\\x08\\x06\\x00\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3378214f314bd1a3693b9daf7677fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Next Step', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "{'img_path': '/data/data1/syc/intern/wanshan/datasets/ScreenSpot/screenspot_imgs/mobile_1ca5b944-293a-46a1-af95-eb35bc8a0b2a.png',\n",
    " 'text': 'check the weather',\n",
    " 'bbox': [0.09449152542372881,\n",
    "  0.0475609756097561,\n",
    "  0.34915254237288135,\n",
    "  0.4091463414634146],\n",
    " 'pred': [0.2, 0.17],\n",
    " 'matched': True,\n",
    " 'response': '{\"action_type\": 4, \"click_point\": (0.20,0.17)}\\n',\n",
    " 'type': 'icon',\n",
    " 'source': 'ios'}\n",
    "\"\"\"\n",
    "# Initialize index\n",
    "sample_idx = 0\n",
    "\n",
    "# Function to update display\n",
    "def update_display():\n",
    "    global sample_idx\n",
    "    \n",
    "    if sample_idx < len(mismatched_idxs):\n",
    "        idx = mismatched_idxs[sample_idx]\n",
    "        naive_sample = naive_data[idx]\n",
    "        uigraph_sample = uigraph_data[idx]\n",
    "        # episode_ref = ground_truth_bbox[episode_index]\n",
    "\n",
    "        sentence_label.value = f\"**Naive Action(s):** {naive_sample}\"\n",
    "        sentece_uigraph_label.value = f\"**UI Graph Action(s):** {uigraph_sample}\"\n",
    "        # Extract click coordinates\n",
    "        try:\n",
    "            click_x, click_y = naive_sample.get(\"pred\", (0, 0))\n",
    "            uigraph_click_x, uigraph_click_y = uigraph_sample.get(\"pred\", (0, 0))\n",
    "            # uigraph_click_y += 0.03\n",
    "        except Exception as e:\n",
    "            click_x, click_y = 0, 0  # Default to top-left corner on error\n",
    "\n",
    "        # get bbox from groundtruth\n",
    "        bbox = naive_sample['bbox']\n",
    "        \n",
    "        # Load and update image\n",
    "        img_path = naive_sample[\"img_path\"]\n",
    "        \n",
    "        _ = load_visualize(img_path)\n",
    "        naive_image_path = draw_click_point(img_path, click_x, click_y, bbox)\n",
    "        uigraph_image_path = draw_click_point(\"./visualize_imgs/demo.png\", uigraph_click_x, uigraph_click_y, bbox, pred=True)\n",
    "        if os.path.exists(img_path):\n",
    "            with open(naive_image_path, \"rb\") as f:\n",
    "                image_widget.value = f.read()\n",
    "            with open(uigraph_image_path, \"rb\") as f:\n",
    "                image_pred.value = f.read()\n",
    "            # image_patch.value = load_visualize(img_path)\n",
    "        else:\n",
    "            sentence_label.value += f\"\\n(Error: Image not found at {img_path})\"\n",
    "    else:\n",
    "        sentence_label.value = \"\"\n",
    "        image_widget.value = b\"\"\n",
    "\n",
    "# Next button function\n",
    "def next_step(_):\n",
    "    global sample_idx\n",
    "    \n",
    "    # Move to the next item in the navigation sequence\n",
    "    if sample_idx < len(mismatched_idxs) - 1:\n",
    "        sample_idx += 1\n",
    "        update_display()\n",
    "\n",
    "\n",
    "    update_display()\n",
    "\n",
    "# Widgets\n",
    "# instruction_label = widgets.HTML()\n",
    "sentence_label = widgets.HTML()\n",
    "sentece_uigraph_label = widgets.HTML()\n",
    "image_widget = widgets.Image(format='png', width=600)  # Set Image Size\n",
    "image_pred = widgets.Image(format='png', width=600)\n",
    "# image_patch = widgets.Image(format='png', width=600)  # Set Image Size\n",
    "\n",
    "# Layout to show images side by side\n",
    "image_box = widgets.HBox([image_widget, image_pred])  # Side-by-side\n",
    "\n",
    "\n",
    "next_button = widgets.Button(description=\"Next Step\")\n",
    "next_button.on_click(next_step)\n",
    "\n",
    "# Initial display\n",
    "update_display()\n",
    "\n",
    "# Layout\n",
    "# display(sentence_label, sentece_uigraph_label,  image_box, image_patch, next_button)\n",
    "display(sentence_label, sentece_uigraph_label,  image_box, next_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen2vl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
