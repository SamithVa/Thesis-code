{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image\n",
    "import os\n",
    "from transformers import Qwen2VLProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import ast  # To safely evaluate JSON-like strings\n",
    "from PIL import Image, ImageDraw\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_click_point(img_path, qwen2vl_x, qwen2vl_y, seeclick_x, seeclick_y, bbox):\n",
    "    \"\"\"\n",
    "    Load an image from img_path and draw two circles and a bounding box:\n",
    "      - Blue circle for the Qwen2VL click at (qwen2vl_x, qwen2vl_y)\n",
    "      - Red circle for the SeeClick click at (seeclick_x, seeclick_y)\n",
    "      - Bounding box is drawn with a green rectangle using relative coordinates provided in bbox \n",
    "        as [x_left, y_left, x_right, y_right]\n",
    "        \n",
    "    Parameters:\n",
    "      img_path: Path to the image file.\n",
    "      qwen2vl_x, qwen2vl_y: Relative coordinates (0-1) of Qwen2VL click.\n",
    "      seeclick_x, seeclick_y: Relative coordinates (0-1) of SeeClick click.\n",
    "      bbox: List of relative coordinates [x_left, y_left, x_right, y_right] for the bounding box.\n",
    "    \n",
    "    Returns:\n",
    "      Annotated image data in PNG format as binary.\n",
    "    \"\"\"\n",
    "    # Open the image and get its dimensions\n",
    "    image = Image.open(img_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    width, height = image.size\n",
    "\n",
    "    # Convert relative click coordinates to absolute coordinates\n",
    "    qwen2vl_abs_x = qwen2vl_x * width\n",
    "    qwen2vl_abs_y = qwen2vl_y * height\n",
    "    seeclick_abs_x = seeclick_x * width\n",
    "    seeclick_abs_y = seeclick_y * height\n",
    "\n",
    "    # Convert relative bbox coordinates to absolute coordinates\n",
    "    bbox_left = bbox[0] * width\n",
    "    bbox_top = bbox[1] * height\n",
    "    bbox_right = bbox[2] * width\n",
    "    bbox_bottom = bbox[3] * height\n",
    "\n",
    "    # Debug print for absolute click coordinates and bbox\n",
    "    # print(\"Qwen2VL click absolute:\", qwen2vl_abs_x, qwen2vl_abs_y)\n",
    "    # print(\"SeeClick click absolute:\", seeclick_abs_x, seeclick_abs_y)\n",
    "    # print(\"BBox absolute:\", bbox_left, bbox_top, bbox_right, bbox_bottom)\n",
    "\n",
    "    # Draw the bounding box on the image (green outline, width 2)\n",
    "    draw.rectangle([bbox_left, bbox_top, bbox_right, bbox_bottom], outline=\"green\", width=2)\n",
    "\n",
    "    # Set a fixed radius for the click point markers\n",
    "    radius = 5  \n",
    "\n",
    "    # Draw the Qwen2VL prediction (blue circle)\n",
    "    draw.ellipse(\n",
    "        (qwen2vl_abs_x - radius, qwen2vl_abs_y - radius,\n",
    "         qwen2vl_abs_x + radius, qwen2vl_abs_y + radius),\n",
    "        fill=\"blue\"\n",
    "    )\n",
    "\n",
    "    # Draw the SeeClick prediction (red circle)\n",
    "    draw.ellipse(\n",
    "        (seeclick_abs_x - radius, seeclick_abs_y - radius,\n",
    "         seeclick_abs_x + radius, seeclick_abs_y + radius),\n",
    "        fill=\"red\"\n",
    "    )\n",
    "\n",
    "    # Save the modified image to a bytes buffer and return the PNG binary data\n",
    "    with io.BytesIO() as output:\n",
    "        image.save(output, format=\"PNG\")\n",
    "        return output.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON file\n",
    "qwen2vl_pred_path = \"/home/syc/intern/wanshan/Thesis_result/Mind2Web/Text-History/Qwen2-VL-7B_naive/qwen2vl_resampler_7b_keep_1_date_0406_website.json\"  # Change this to your JSON file path\n",
    "# json_file = \"/home/syc/intern/wanshan/Qwen2-VL/agent_tasks/custom_training_script/qwen2vl_train_train.json\"\n",
    "with open(qwen2vl_pred_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "# Filter instances where Ele_match is False\n",
    "qwen2vl_data = [\n",
    "    [step for step in episode] \n",
    "    for episode in data\n",
    "]\n",
    "\n",
    "# Initialize index\n",
    "episode_index = 0\n",
    "step_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeclick_pred_path = \"/home/syc/intern/wanshan/SeeClick/visualize_result/seeclick_mind2map_ckpt_4000/seeclick_mind2web_website.json\"\n",
    "with open(seeclick_pred_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "# Filter instances where Ele_match is False\n",
    "seeclick_data = [\n",
    "    [step for step in episode] \n",
    "    for episode in data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qwen2vl_data[0]), len(seeclick_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.278, 0.64, 0.528, 0.688]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ground_truth_path = \"/home/syc/intern/wanshan/Qwen2-VL/data/subset_100_samples.json\"\n",
    "# with open(ground_truth_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#     ground_truth_data = json.load(f)\n",
    "\n",
    "qwen2vl_data[0][0]['bbox_ref'] # x_left, y_left, x_right, y_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "navigation_sequence  = []\n",
    "for episode_idx, episode in enumerate(qwen2vl_data):\n",
    "    for step_idx, step in enumerate(episode):\n",
    "        if step['Ele_match'] == True and seeclick_data[episode_idx][step_idx]['Ele_match'] == False:\n",
    "            navigation_sequence.append((episode_idx, step_idx))\n",
    "sequence_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(navigation_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ea31857afb493cacdade224fcc91dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cb5a2066bb4700b881e32d99df4654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836f225130d14e16b30fb81a2d5a6211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', width='1000')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f95e65c2ee549f29cc10981ec28fea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Next Step', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def update_display():\n",
    "    global sequence_index\n",
    "    \n",
    "    if sequence_index < len(navigation_sequence):\n",
    "        episode_index, step_index = navigation_sequence[sequence_index]\n",
    "        episode_qwen2vl = qwen2vl_data[episode_index]\n",
    "        episode_seeclick = seeclick_data[episode_index]\n",
    "\n",
    "        # Ensure that the step index is valid for the current episode\n",
    "        if step_index < len(episode_qwen2vl):\n",
    "            step_qwen2vl = episode_qwen2vl[step_index]\n",
    "            step_seeclick = episode_seeclick[step_index]\n",
    "            \n",
    "            # Update the text for each prediction\n",
    "            sentence_qwen2vl.value = f\"**Qwen2VL Action(s):** {step_qwen2vl}\"\n",
    "            sentence_seeclick.value = f\"**SeeClick Action(s):** {step_seeclick}\"\n",
    "            \n",
    "            # Extract click coordinates from the sentence JSON data\n",
    "            try:\n",
    "                action_data_qwen2vl = ast.literal_eval(step_qwen2vl[\"sentence\"][0])\n",
    "                qwen2vl_click_x, qwen2vl_click_y = action_data_qwen2vl.get(\"click_point\", (0, 0))\n",
    "                bbox = step_qwen2vl.get(\"bbox_ref\", None)\n",
    "                \n",
    "                action_data_seeclick = ast.literal_eval(step_seeclick[\"sentence\"])\n",
    "                seeclick_click_x, seeclick_click_y = action_data_seeclick.get(\"click_point\", (0, 0))\n",
    "            except Exception as e:\n",
    "                # If extraction fails, default to top-left for both\n",
    "                qwen2vl_click_x, qwen2vl_click_y = 0, 0\n",
    "                seeclick_click_x, seeclick_click_y = 0, 0\n",
    "            \n",
    "            # Load the image from the Qwen2VL step (assuming it's the same image used by SeeClick)\n",
    "            img_path = step_qwen2vl[\"img_path\"]\n",
    "            \n",
    "            if os.path.exists(img_path):\n",
    "                # Draw both click points on the image and update the widget\n",
    "                modified_img_bytes = draw_click_point(img_path, qwen2vl_click_x, qwen2vl_click_y,\n",
    "                                                      seeclick_click_x, seeclick_click_y, bbox)\n",
    "                image_widget.value = modified_img_bytes\n",
    "            else:\n",
    "                sentence_qwen2vl.value += f\"\\n(Error: Image not found at {img_path})\"\n",
    "        else:\n",
    "            sentence_qwen2vl.value = \"No more steps in this episode.\"\n",
    "            image_widget.value = b\"\"\n",
    "    else:\n",
    "        sentence_qwen2vl.value = \"\"\n",
    "        image_widget.value = b\"\"\n",
    "\n",
    "def next_step(_):\n",
    "    global sequence_index\n",
    "    # Move to the next item in the navigation sequence if available\n",
    "    if sequence_index < len(navigation_sequence) - 1:\n",
    "        sequence_index += 1\n",
    "    update_display()\n",
    "\n",
    "# Widgets initialization\n",
    "sentence_qwen2vl = widgets.HTML()\n",
    "sentence_seeclick = widgets.HTML()\n",
    "image_widget = widgets.Image(format='png', width=1000)  # Single image widget for merged output\n",
    "next_button = widgets.Button(description=\"Next Step\")\n",
    "next_button.on_click(next_step)\n",
    "\n",
    "# Initial display update and layout\n",
    "display(sentence_qwen2vl, sentence_seeclick, image_widget, next_button)\n",
    "update_display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen2vl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
